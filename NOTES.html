# build and run docker container from https://ollama.com/blog/ollama-is-now-available-as-an-official-docker-image

docker run -d -v ollama_storage:/root/.ollama -p 11434:11434 --name ollama ollama/ollama

# and use docker start ollama afterwards

# then go into the container and pull a model like llama:3.2

docker exec ollama bash -c "ollama pull llama3.2"

# to make a request

curl http://localhost:11434/api/generate -d '{
  "model": "llama3.2",
  "prompt":" Why is the colour of sea blue ?"
}'

# now build a little web app to chat




# before 2024-10-17
# TODO overhaul ui




# 2024-10-17
# use local https://www.youtube.com/watch?v=FQTCLOUnIzI https://github.com/technovangelist/videoprojects/tree/2dd82eb1d8012e196f2e80b867744ebd42a10281/2024-09-10-buildrag/python
# to give rag capabilities using chrome docker container
# run latest chroma container on port 8000
docker run -d -p 8000:8000 -v chroma-data:/chromadb/data chromadb/chroma





